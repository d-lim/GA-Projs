{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Mobility Prediction\n",
    "\n",
    "Welcome to my project on Human Mobility Prediction. For the introduction of my project and overview of what will be covered in this notebook and the subsequent others, please click [here](https://d-lim.github.io/indigo-jekyll-theme/). \n",
    "\n",
    "## 1. Cleaning the dataset\n",
    "In this first notebook, initial cleaning process:\n",
    "* Removing duplicates and homogenous features\n",
    "* Transforming \"POLYLINE\" datatype \n",
    "* Extracting start and end coordinates\n",
    "* Extracting datetime information will be carried out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi = pd.read_csv(\"../train.csv\") #import train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derrick_lim1991/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/derrick_lim1991/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# 1. Write initial_clean function and use to remove duplicates and columns which contain homogeneous values\n",
    "def initial_clean(df, keep_last = \"last\"):\n",
    "    '''\n",
    "    Basic cleaning which consists of droping off duplicates,\n",
    "    and columns which contain homogeneous values.\n",
    "    '''\n",
    "    df.drop_duplicates(subset = \"TRIP_ID\", keep = keep_last, inplace = True) #TRIP_ID duplicates are dropped as TRIP_IDs are unique\n",
    "    df = df[df[\"MISSING_DATA\"] == 0] #Remove all data with missing coordinates\n",
    "    df.drop(\"MISSING_DATA\", axis = 1, inplace = True) #All missing coordinates removed, MISSING_DATA column can be removed\n",
    "    df.drop(\"DAY_TYPE\", axis = 1, inplace=True) #DAY_TYPE is removed as all values are 'A'\n",
    "    df = df[df[\"POLYLINE\"] != \"[]\"]\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "taxi = initial_clean(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Write both list_coordiantes and convert_coordinates function to use them both to convert 'POLYLINE' from a str into a list.\n",
    "import json \n",
    "def list_coordinates(string):\n",
    "        \"\"\"\n",
    "        Loads list of coordinates from given string and swap out longitudes & latitudes.\n",
    "        Swapping is done because the standard is to have latitude values first, but\n",
    "        the coordiantes given is backwards.\n",
    "        \"\"\"\n",
    "        return [(lat, long) for (long, lat) in json.loads(string)] # json.loads convent strs into a json object (i.e list/dict)\n",
    "def convert_coordinates(df):\n",
    "    \"\"\"\n",
    "    Transforming the POLYLINE values from a string into a list\n",
    "    \"\"\"\n",
    "    df['POLYLINE'] = df['POLYLINE'].apply(list_coordinates) #maps through and coverts str into list for each row in 'POLYLINE' \n",
    "    return df\n",
    "\n",
    "taxi = convert_coordinates(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. Write start_pos function and use it to extract the coordinates for the start point\n",
    "def start_pos(df):\n",
    "    \"\"\"\n",
    "    Returns back the first lat and longs in the 'POLYLINE' in two seperate\n",
    "    columns, with labels 'START_LAT' for latitudes and 'START_LONG'\n",
    "    for longitudes.\n",
    "    \"\"\"\n",
    "    df['START_LAT'] = df['POLYLINE'].apply(lambda x: x[0][0]) #extracts the first latitude in the polyline\n",
    "    df['START_LONG'] = df['POLYLINE'].apply(lambda x: x[0][1])#extracts the first longitude in the polyline\n",
    "    return df\n",
    "\n",
    "taxi = start_pos(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4. Write last_pos function and use it to extract the last coordinate for of the 'POLYLINE'\n",
    "# Note: last_pos() extracts destination for the training set but last coordiante of truncated 'POLYLINE' for test set\n",
    "def last_pos(df, lat_label, long_label):\n",
    "    \"\"\"\n",
    "    Returns back the last lat and longs in the 'POLYLINE' in two seperate\n",
    "    columns, with labels define in lat_label for latitudes \n",
    "    and long_label for longitudes.\n",
    "    \"\"\"\n",
    "    df[lat_label] = df['POLYLINE'].apply(lambda x: x[-1][0])\n",
    "    df[long_label] = df['POLYLINE'].apply(lambda x: x[-1][1])\n",
    "    return df\n",
    "\n",
    "taxi = last_pos(taxi, \"END_LAT\", \"END_LONG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. Write date_time function and use it to extract the week, day and quarter hour of the trips\n",
    "def date_time(df):\n",
    "    \"\"\"\n",
    "    Convert unxi time in seconds to datetime and spliting them\n",
    "    into 'WEEK', 'DAY', 'HOUR'\n",
    "    \"\"\"\n",
    "    df['date_time'] = pd.to_datetime(df['TIMESTAMP'],unit='s')\n",
    "    df[\"WEEK\"] = df[\"date_time\"].map(lambda x : x.weekofyear) #total 52 weeks in a year\n",
    "    df[\"DAY\"] = df[\"date_time\"].map(lambda x : x.dayofweek) # total 7 days in a week Mon = 0 and Sun = 6\n",
    "    df[\"Q_HOUR\"] = df[\"date_time\"].map(lambda x : x.hour* 4 + x.minute / 15) \n",
    "    return df\n",
    "\n",
    "taxi = date_time(taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another than the training set, cleaning will be applied to the test set too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = initial_clean(test)\n",
    "test = convert_coordinates(test)\n",
    "taxi = last_pos(taxi, \"END_LAT\", \"END_LONG\")\n",
    "test = start_pos(test)\n",
    "test = date_time(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi.to_pickle('./Pickles/taxi_cleaned') #pickling cleaned trainset for to be used for EDA\n",
    "test.to_pickle('./Pickles/test_cleaned') #pickling cleaned testset for to be used for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
