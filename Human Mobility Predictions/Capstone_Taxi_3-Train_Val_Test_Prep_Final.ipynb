{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preparing Datasets for Prediction Modelling\n",
    "In this notebook, the dataset which have been cleaned and analysed will have to be prepared before we can run our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives:\n",
    " - Encode catergorical features\n",
    " - Create test and validation sets\n",
    " - Extracting required \"POLYLINE\" coordinates from test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing both train and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi = pd.read_pickle('./Pickles/taxi_EDA_completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_pickle('./Pickles/test_EDA_completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding catergorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding catergorical columns is a good practice as most algorithm packages do not take in str. The catergorical features in our dataset are TRIP_ID, CALL_TYPE, ORIGIN_CALL, TIMESTAMP  , TAXI_ID , WEEK , DAY , Q_HOUR.  \n",
    "\n",
    "Of these, only CALL_TYPE is required to be encoded as the values of CALL_TYPE is in a str format. For encoding, label encoder from sklearn is chosen as it encode classes with value between 0 and n_classes-1. In addition, it is important to encode both train and test dataset together as there might be classes present are only in train/test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#concatinating  both train and test \"CALL_TYPE\" to ensure that all classes are captured in our encoder\n",
    "total_call_type = pd.DataFrame(pd.concat([taxi[\"CALL_TYPE\"], test[\"CALL_TYPE\"]])) \n",
    "call_type_encoder = preprocessing.LabelEncoder().fit(total_call_type[\"CALL_TYPE\"])\n",
    "\n",
    "#encoding class labels for both train and test sets\n",
    "taxi[\"CALL_TYPE\"] = call_type_encoder.transform(taxi[\"CALL_TYPE\"])\n",
    "test[\"CALL_TYPE\"] = call_type_encoder.transform(test[\"CALL_TYPE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a test and validation set\n",
    "As the given test set contains 320 truncated trips, we will split our training data into train and valiadation sets. The ratio chosen is train(99.9% - 1,580,976 trips) and validation(0.1% - 1,581 trips). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "def train_val_split(df):\n",
    "    '''\n",
    "    Splitting up the training set into 99.9% train/0.1% test test.\n",
    "    '''\n",
    "    df = shuffle(df, random_state = 0).reset_index(drop=True) #shuffle the dataset before splitting\n",
    "    val_thirty = df.shape[0] - int(0.001 * df.shape[0]) + 1\n",
    "    print val_thirty , df.shape[0] - val_thirty\n",
    "    train = df.iloc[:val_thirty].reset_index(drop=True)\n",
    "    val = df.iloc[val_thirty:].reset_index(drop=True)\n",
    "    return train , val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580976 1581\n"
     ]
    }
   ],
   "source": [
    "train , val = train_val_split(taxi) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aftering splittig the training data into train and val sets, the polyline coordinates of the val set have to be truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_truncate(df, polyline):\n",
    "    \"\"\"\n",
    "    Randomly truncate the end of the trip's polyline points to simulate partial trips.\n",
    "    This is only to create a validation dataset.\n",
    "    Note: If there is only one coordiante, no truncation will be carried out\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    return df[polyline].map(lambda x: x[:np.random.randint(1, len(x))] if len(x) > 1 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val[\"POLYLINE\"] = random_truncate(val, \"POLYLINE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting required \"POLYLINE\" coordinates from test and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extensive research, only the first and last few coordinates is essential determine the taxi's destination. From research done by University of South Florida, five coordinates is required to conduct trajectory prediction analysis. Therefore, we shall use only the five and last five coordinates for our destination prediction. \n",
    "\n",
    "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.391.8313&rep=rep1&type=pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our train, val and test sets, the start and end coordinates have already been extracted. Therefore, only the subsequent 4 coordinates after start and last 4 coordinates before end are required to be extracted. \n",
    "\n",
    "For the train set, the last coordinate in the \"POLYLINE\" refers to our y-label, however for the val and test sets, the \"POLYLINE\" coordinates are already truncated, which means the last coordinate in the test is not our y-label. Therefore, to tackle this, two seperate functions are written for extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_train(df):\n",
    "    \"\"\"\n",
    "    Extract next 4 coordinates after start \n",
    "    and last 4 coordinates before end for train set\n",
    "    \"\"\"\n",
    "    train_lat_2 = []\n",
    "    train_lat_3 = []\n",
    "    train_lat_4 = []\n",
    "    train_lat_5 = []\n",
    "    \n",
    "    train_long_2 = []\n",
    "    train_long_3 = []\n",
    "    train_long_4 = []\n",
    "    train_long_5 = []\n",
    "\n",
    "    for x in df[\"POLYLINE\"]:\n",
    "        if len(x) >= 5: \n",
    "            train_lat_2.append(x[1][0])\n",
    "            train_lat_3.append(x[2][0])\n",
    "            train_lat_4.append(x[3][0])\n",
    "            train_lat_5.append(x[4][0])\n",
    "                              \n",
    "            train_long_2.append(x[1][1])\n",
    "            train_long_3.append(x[2][1])\n",
    "            train_long_4.append(x[3][1])\n",
    "            train_long_5.append(x[4][1])\n",
    "            \n",
    "        \n",
    "        if len(x) == 4: \n",
    "            train_lat_2.append(x[1][0])\n",
    "            train_lat_3.append(x[2][0])\n",
    "            train_lat_4.append(x[3][0])\n",
    "            train_lat_5.append(x[3][0])\n",
    "                              \n",
    "            train_long_2.append(x[1][1])\n",
    "            train_long_3.append(x[2][1])\n",
    "            train_long_4.append(x[3][1])\n",
    "            train_long_5.append(x[3][1])\n",
    "                                \n",
    "        if len(x) == 3: \n",
    "            train_lat_2.append(x[1][0])\n",
    "            train_lat_3.append(x[2][0])\n",
    "            train_lat_4.append(x[2][0])\n",
    "            train_lat_5.append(x[2][0])\n",
    "                              \n",
    "            train_long_2.append(x[1][1])\n",
    "            train_long_3.append(x[2][1])\n",
    "            train_long_4.append(x[2][1])\n",
    "            train_long_5.append(x[2][1])\n",
    "        \n",
    "        if len(x) == 2: \n",
    "            train_lat_2.append(x[1][0])\n",
    "            train_lat_3.append(x[1][0])\n",
    "            train_lat_4.append(x[1][0])\n",
    "            train_lat_5.append(x[1][0])\n",
    "                              \n",
    "            train_long_2.append(x[1][1])\n",
    "            train_long_3.append(x[1][1])\n",
    "            train_long_4.append(x[1][1])\n",
    "            train_long_5.append(x[1][1]) \n",
    "            \n",
    "        if len(x) == 1: \n",
    "            train_lat_2.append(x[0][0])\n",
    "            train_lat_3.append(x[0][0])\n",
    "            train_lat_4.append(x[0][0])\n",
    "            train_lat_5.append(x[0][0])\n",
    "                              \n",
    "            train_long_2.append(x[0][1])\n",
    "            train_long_3.append(x[0][1])\n",
    "            train_long_4.append(x[0][1])\n",
    "            train_long_5.append(x[0][1])\n",
    "        \n",
    "                                \n",
    "    df[\"LAT_2\"] = pd.DataFrame(train_lat_2)\n",
    "    df[\"LAT_3\"] = pd.DataFrame(train_lat_3)\n",
    "    df[\"LAT_4\"] = pd.DataFrame(train_lat_4)\n",
    "    df[\"LAT_5\"] = pd.DataFrame(train_lat_5)  \n",
    "                              \n",
    "    df[\"LONG_2\"] = pd.DataFrame(train_long_2)\n",
    "    df[\"LONG_3\"] = pd.DataFrame(train_long_3)\n",
    "    df[\"LONG_4\"] = pd.DataFrame(train_long_4)\n",
    "    df[\"LONG_5\"] = pd.DataFrame(train_long_5)\n",
    "    \n",
    "    print \"First LATs, LONGs extracted\"   \n",
    "    \n",
    "    train_lat_2_last = []\n",
    "    train_lat_3_last = []\n",
    "    train_lat_4_last = []\n",
    "    train_lat_5_last = []\n",
    "                              \n",
    "    train_long_2_last = []\n",
    "    train_long_3_last = []\n",
    "    train_long_4_last = []\n",
    "    train_long_5_last = []\n",
    "\n",
    "    for x in df[\"POLYLINE\"]:\n",
    "        if len(x) >= 5: \n",
    "            train_lat_2_last.append(x[-2][0])\n",
    "            train_lat_3_last.append(x[-3][0])\n",
    "            train_lat_4_last.append(x[-4][0])\n",
    "            train_lat_5_last.append(x[-5][0])\n",
    "                                                         \n",
    "            train_long_2_last.append(x[-2][1])\n",
    "            train_long_3_last.append(x[-3][1])\n",
    "            train_long_4_last.append(x[-4][1])\n",
    "            train_long_5_last.append(x[-5][1])\n",
    "        \n",
    "        if len(x) == 4: \n",
    "            train_lat_2_last.append(x[-2][0])\n",
    "            train_lat_3_last.append(x[-3][0])\n",
    "            train_lat_4_last.append(x[-4][0])\n",
    "            train_lat_5_last.append(x[-4][0])\n",
    "                                   \n",
    "            train_long_2_last.append(x[-2][1])\n",
    "            train_long_3_last.append(x[-3][1])\n",
    "            train_long_4_last.append(x[-4][1])\n",
    "            train_long_5_last.append(x[-4][1])\n",
    "                                \n",
    "        if len(x) == 3:  \n",
    "            train_lat_2_last.append(x[-2][0])\n",
    "            train_lat_3_last.append(x[-3][0])\n",
    "            train_lat_4_last.append(x[-3][0])\n",
    "            train_lat_5_last.append(x[-3][0])\n",
    "                                   \n",
    "            train_long_2_last.append(x[-2][1])\n",
    "            train_long_3_last.append(x[-3][1])\n",
    "            train_long_4_last.append(x[-3][1])\n",
    "            train_long_5_last.append(x[-3][1])\n",
    "        \n",
    "        if len(x) == 2: \n",
    "            train_lat_2_last.append(x[-2][0])\n",
    "            train_lat_3_last.append(x[-2][0])\n",
    "            train_lat_4_last.append(x[-2][0])\n",
    "            train_lat_5_last.append(x[-2][0])\n",
    "                                   \n",
    "            train_long_2_last.append(x[-2][1])\n",
    "            train_long_3_last.append(x[-2][1])\n",
    "            train_long_4_last.append(x[-2][1])\n",
    "            train_long_5_last.append(x[-2][1])\n",
    "        \n",
    "        if len(x) == 1: \n",
    "            train_lat_2_last.append(x[-1][0])\n",
    "            train_lat_3_last.append(x[-1][0])\n",
    "            train_lat_4_last.append(x[-1][0])\n",
    "            train_lat_5_last.append(x[-1][0])\n",
    "                                   \n",
    "            train_long_2_last.append(x[-1][1])\n",
    "            train_long_3_last.append(x[-1][1])\n",
    "            train_long_4_last.append(x[-1][1])\n",
    "            train_long_5_last.append(x[-1][1])\n",
    "                                   \n",
    "                              \n",
    "    df[\"LAT_2_last\"] = pd.DataFrame(train_lat_2_last)\n",
    "    df[\"LAT_3_last\"] = pd.DataFrame(train_lat_3_last)\n",
    "    df[\"LAT_4_last\"] = pd.DataFrame(train_lat_4_last)\n",
    "    df[\"LAT_5_last\"] = pd.DataFrame(train_lat_5_last)\n",
    "                                   \n",
    "    df[\"LONG_2_last\"] = pd.DataFrame(train_long_2_last)\n",
    "    df[\"LONG_3_last\"] = pd.DataFrame(train_long_3_last)\n",
    "    df[\"LONG_4_last\"] = pd.DataFrame(train_long_4_last)\n",
    "    df[\"LONG_5_last\"] = pd.DataFrame(train_long_5_last)\n",
    "    \n",
    "    print \"Last LATs, LONGs extracted\"\n",
    "    print \"Train set extraction completed!\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_test(df):\n",
    "    \"\"\"\n",
    "    Extract next 3 coordinates after start \n",
    "    and last 3 coordinates before end for test set\n",
    "    \"\"\"\n",
    "    test_lat_2 = []\n",
    "    test_lat_3 = []\n",
    "    test_lat_4 = []\n",
    "    test_lat_5 = []\n",
    "    \n",
    "    test_long_2 = []\n",
    "    test_long_3 = []\n",
    "    test_long_4 = []\n",
    "    test_long_5 = []\n",
    "\n",
    "    for x in df[\"POLYLINE\"]:\n",
    "        if len(x) >= 5:\n",
    "            test_lat_2.append(x[1][0])\n",
    "            test_lat_3.append(x[2][0])\n",
    "            test_lat_4.append(x[3][0])\n",
    "            test_lat_5.append(x[4][0])\n",
    "                              \n",
    "            test_long_2.append(x[1][1])\n",
    "            test_long_3.append(x[2][1])\n",
    "            test_long_4.append(x[3][1])\n",
    "            test_long_5.append(x[4][1])\n",
    "            \n",
    "        if len(x) == 4:\n",
    "            test_lat_2.append(x[1][0])\n",
    "            test_lat_3.append(x[2][0])\n",
    "            test_lat_4.append(x[3][0])\n",
    "            test_lat_5.append(x[3][0])\n",
    "                              \n",
    "            test_long_2.append(x[1][1])\n",
    "            test_long_3.append(x[2][1])\n",
    "            test_long_4.append(x[3][1])\n",
    "            test_long_5.append(x[3][1])\n",
    "                                \n",
    "        if len(x) == 3:\n",
    "            test_lat_2.append(x[1][0])\n",
    "            test_lat_3.append(x[2][0])\n",
    "            test_lat_4.append(x[2][0])\n",
    "            test_lat_5.append(x[2][0])\n",
    "                              \n",
    "            test_long_2.append(x[1][1])\n",
    "            test_long_3.append(x[2][1])\n",
    "            test_long_4.append(x[2][1])\n",
    "            test_long_5.append(x[2][1])\n",
    "        \n",
    "        if len(x) == 2:\n",
    "            test_lat_2.append(x[1][0])\n",
    "            test_lat_3.append(x[1][0])\n",
    "            test_lat_4.append(x[1][0])\n",
    "            test_lat_5.append(x[1][0])\n",
    "                              \n",
    "            test_long_2.append(x[1][1])\n",
    "            test_long_3.append(x[1][1])\n",
    "            test_long_4.append(x[1][1])\n",
    "            test_long_5.append(x[1][1])\n",
    "        \n",
    "        if len(x) ==1:\n",
    "            test_lat_2.append(x[0][0])\n",
    "            test_lat_3.append(x[0][0])\n",
    "            test_lat_4.append(x[0][0])\n",
    "            test_lat_5.append(x[0][0])\n",
    "                              \n",
    "            test_long_2.append(x[0][1])\n",
    "            test_long_3.append(x[0][1])\n",
    "            test_long_4.append(x[0][1])\n",
    "            test_long_5.append(x[0][1])\n",
    "                                \n",
    "    df[\"LAT_2\"] = pd.DataFrame(test_lat_2)\n",
    "    df[\"LAT_3\"] = pd.DataFrame(test_lat_3)\n",
    "    df[\"LAT_4\"] = pd.DataFrame(test_lat_4)\n",
    "    df[\"LAT_5\"] = pd.DataFrame(test_lat_5)\n",
    "                              \n",
    "    df[\"LONG_2\"] = pd.DataFrame(test_long_2)\n",
    "    df[\"LONG_3\"] = pd.DataFrame(test_long_3)\n",
    "    df[\"LONG_4\"] = pd.DataFrame(test_long_4)\n",
    "    df[\"LONG_5\"] = pd.DataFrame(test_long_5) \n",
    "    \n",
    "    print \"First LATs, LONGs extracted\"   \n",
    "    \n",
    "    test_lat_2_last = []\n",
    "    test_lat_3_last = []\n",
    "    test_lat_4_last = []\n",
    "    test_lat_5_last = []\n",
    "    \n",
    "    test_long_2_last = []\n",
    "    test_long_3_last = []\n",
    "    test_long_4_last = []\n",
    "    test_long_5_last = []\n",
    "\n",
    "    for x in df[\"POLYLINE\"]:\n",
    "        if len(x) >= 5:\n",
    "            test_lat_2_last.append(x[-1][0])\n",
    "            test_lat_3_last.append(x[-2][0])\n",
    "            test_lat_4_last.append(x[-3][0])\n",
    "            test_lat_5_last.append(x[-4][0])\n",
    "                                   \n",
    "            test_long_2_last.append(x[-1][1])\n",
    "            test_long_3_last.append(x[-2][1])\n",
    "            test_long_4_last.append(x[-3][1])\n",
    "            test_long_5_last.append(x[-4][1])\n",
    "        \n",
    "        if len(x) == 4:\n",
    "            test_lat_2_last.append(x[-1][0])\n",
    "            test_lat_3_last.append(x[-2][0])\n",
    "            test_lat_4_last.append(x[-3][0])\n",
    "            test_lat_5_last.append(x[-4][0])\n",
    "                                   \n",
    "            test_long_2_last.append(x[-1][1])\n",
    "            test_long_3_last.append(x[-2][1])\n",
    "            test_long_4_last.append(x[-3][1])\n",
    "            test_long_5_last.append(x[-4][1])\n",
    "                                \n",
    "        if len(x) == 3:\n",
    "            test_lat_2_last.append(x[-1][0])\n",
    "            test_lat_3_last.append(x[-2][0])\n",
    "            test_lat_4_last.append(x[-3][0])\n",
    "            test_lat_5_last.append(x[-3][0])\n",
    "                                   \n",
    "            test_long_2_last.append(x[-1][1])\n",
    "            test_long_3_last.append(x[-2][1])\n",
    "            test_long_4_last.append(x[-3][1])\n",
    "            test_long_5_last.append(x[-3][1])\n",
    "        \n",
    "        if len(x) == 2:\n",
    "            test_lat_2_last.append(x[-1][0])\n",
    "            test_lat_3_last.append(x[-2][0])\n",
    "            test_lat_4_last.append(x[-2][0])\n",
    "            test_lat_5_last.append(x[-2][0])\n",
    "                                   \n",
    "            test_long_2_last.append(x[-1][1])\n",
    "            test_long_3_last.append(x[-2][1])\n",
    "            test_long_4_last.append(x[-2][1])\n",
    "            test_long_5_last.append(x[-2][1])\n",
    "        \n",
    "        if len(x) == 1:\n",
    "            test_lat_2_last.append(x[-1][0])\n",
    "            test_lat_3_last.append(x[-1][0])\n",
    "            test_lat_4_last.append(x[-1][0])\n",
    "            test_lat_5_last.append(x[-1][0])\n",
    "                                   \n",
    "            test_long_2_last.append(x[-1][1])\n",
    "            test_long_3_last.append(x[-1][1])\n",
    "            test_long_4_last.append(x[-1][1])\n",
    "            test_long_5_last.append(x[-1][1])\n",
    "                                   \n",
    "                              \n",
    "    df[\"LAT_2_last\"] = pd.DataFrame(test_lat_2_last)\n",
    "    df[\"LAT_3_last\"] = pd.DataFrame(test_lat_3_last)\n",
    "    df[\"LAT_4_last\"] = pd.DataFrame(test_lat_4_last)\n",
    "    df[\"LAT_5_last\"] = pd.DataFrame(test_lat_5_last)\n",
    "                                   \n",
    "    df[\"LONG_2_last\"] = pd.DataFrame(test_long_2_last)\n",
    "    df[\"LONG_3_last\"] = pd.DataFrame(test_long_3_last)\n",
    "    df[\"LONG_4_last\"] = pd.DataFrame(test_long_4_last)\n",
    "    df[\"LONG_5_last\"] = pd.DataFrame(test_long_5_last)\n",
    "    \n",
    "    print \"Last LATs, LONGs extracted\"\n",
    "    print \"Val/Test set extraction completed!\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First LATs, LONGs extracted\n",
      "Last LATs, LONGs extracted\n",
      "Train set extraction completed!\n",
      "First LATs, LONGs extracted\n",
      "Last LATs, LONGs extracted\n",
      "Val/Test set extraction completed!\n",
      "First LATs, LONGs extracted\n",
      "Last LATs, LONGs extracted\n",
      "Val/Test set extraction completed!\n"
     ]
    }
   ],
   "source": [
    "train = extract_train(train)\n",
    "val = extract_test(val)\n",
    "test = extract_test(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing \"END_LAT\" & \"END_LONG\"  in test set as that is now represented with \"LAT_2_last\" & \"LONG_2_last\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.drop(['END_LAT','END_LONG'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure there is no leakage of data, the distance and duration must be recalculated for the val set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val.drop(['DURATION','DISTANCE','DURATION_LOG','DISTANCE_LOG'], axis=1 ,inplace=True)  \n",
    "\n",
    "def haversine(start_long, start_lat, end_long, end_lat):\n",
    "    '''\n",
    "    Using haversine formula to calculate distance in km\n",
    "    between two lat,long coordinates.\n",
    "    '''\n",
    "    EARTH_RADIUS = 6371 #6,371 km is the approximate distance from Earth's center to its surface \n",
    "    start_long = np.radians(start_long)\n",
    "    start_lat = np.radians(start_lat)\n",
    "    end_long = np.radians(end_long)\n",
    "    end_lat = np.radians(end_lat)\n",
    "\n",
    "    dlong = end_long - start_long\n",
    "    dlat = end_lat - start_lat\n",
    "\n",
    "    a = (np.sin(dlat / 2)**2 + np.cos(start_lat) * np.cos(end_lat) *\n",
    "         np.sin(dlong / 2)**2)\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "    return np.nan_to_num(c * EARTH_RADIUS)\n",
    "\n",
    "val[\"DISTANCE\"] = haversine(val['START_LONG'],val['START_LAT'], val['END_LONG'], val['END_LAT'])\n",
    "\n",
    "\n",
    "def duration(df):\n",
    "    \"\"\"    \n",
    "    The time difference between each coordinate \n",
    "    in \"POLYLINE\" is 15s. We get the duration by\n",
    "    taking the len of list * 15s - 15(subtract 15 as first \n",
    "    coordinate is start of trip)\n",
    "    \"\"\"\n",
    "    return df[\"POLYLINE\"].map(lambda x: len(x)*15 - 15)\n",
    "\n",
    "val[\"DURATION\"] = duration(val)\n",
    "\n",
    "def replace_zero(df,col,value=1):\n",
    "    '''\n",
    "    Changes 0 to 1 as log 0 is undefined\n",
    "    '''\n",
    "    df[col].replace(to_replace = 0, value = value, inplace = True)\n",
    "    return df[col]\n",
    "\n",
    "val[\"DURATION\"] = replace_zero(val,\"DURATION\")\n",
    "val[\"DISTANCE\"] = replace_zero(val,\"DISTANCE\")\n",
    "\n",
    "val['DURATION_LOG'] = val['DURATION'].map(lambda x : np.log(x))\n",
    "val['DISTANCE_LOG'] = val['DISTANCE'].map(lambda x : np.log(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickling train, val and test sets for Part 4:\n",
    "- [Capstone_Taxi_4.1-Tree_Based_Models]('./Capstone_Taxi_4.1-Tree_Based_Models')\n",
    "- [Capstone_Taxi_Model4.2_Artificial_Neural_Network]('./Capstone_Taxi_Model4.2_Artificial_Neural_Network.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_pickle('./Pickles/train')\n",
    "val.to_pickle('./Pickles/val')\n",
    "test.to_pickle('./Pickles/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
