{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement: \n",
    "## \"If only we/i knew you were coming... We could/I would...\"\n",
    "\n",
    "Ever use or get the above response from another? I believe most of us have right? With advancement of communication devices, we would have presumed that this issue could be resolved just by informing the other party ahead of time but let's be honest, that isn't always the case. \n",
    "\n",
    "Furthermore, for businesses, most of their customers don't usually do so, all which if only they knew, customer services levels can be elevated and services can be further optimised. Some examples are:\n",
    "\n",
    "Vehicle Rental Companies:\n",
    "Most vehicle rental companies require their customers to return their rental vehicles back to the same place. However if a rental company can predict where their customers are going to be at the end of their rental period, they can offer the next potential customer within the vicinity to take over the vehicle. Therefore customers need not return the vehicles to the same location which they get them from.  \n",
    "\n",
    "Taxi Companies:\n",
    "Unlike companies like Uber, Lyft, Grab and Go, taxi dispatchers usually do not know where a taxi ride is going to end. If taxi dispatchers can predict the destination of a ride, new trips which are around the vincity of the destination can be assigned to the taxi onroute, optimising taxi \n",
    "\n",
    "Brick and Motar Retail Stores:\n",
    "Special promotions can be sent to people who are going to be around the vicnity of their store to entice them to visit their store to potentially increase sales. \n",
    "\n",
    "Customer Centric Establishments: \n",
    "Customer experience can be elavated if an establishment can predict if a customer is dropping by in advance by preparing something bespoke to surprise them upon their arrival.\n",
    "\n",
    "\n",
    "\n",
    "# Proposed Solution:\n",
    "## Predicting where someone would go\n",
    "\n",
    "As the problem lies with people not informing others about their end locations, predictions on end locations have to be deducted from from a series of sources. \n",
    "\n",
    "Hypothesis: Data required are of but not limited to the following:\n",
    "\n",
    "Minimum data features required:\n",
    "Datetime and location of an individual - How: Most devices comes with with a gps tracker nowadays\n",
    "\n",
    "More specific information unique to the type of bussiness one is targeting can be supplimented to increase accurary of predictions. \n",
    "Weather information can be supplied\n",
    "Etc\n",
    "\n",
    "In order to prove my hypothesis, after searching through various sources, a [dataset](https://www.kaggle.com/c/pkdd-15-predict-taxi-service-trajectory-i) with required information was found from Kaggle.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# METADATA\n",
    "\n",
    "![Metadata]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Taxi Destinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://35.198.196.146:5000/files/taxi/porto_01_big.jpg\" alt=\"Drawing\" style=\"width: 1500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "taxi = pd.read_csv(\"../train.csv\") #import train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/derrick_lim1991/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/derrick_lim1991/anaconda3/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# 1. Write initial_clean function and use to remove duplicates and columns which contain homogeneous values\n",
    "def initial_clean(df, keep_last = \"last\"):\n",
    "    '''\n",
    "    Basic cleaning which consists of droping off duplicates,\n",
    "    and columns which contain homogeneous values.\n",
    "    '''\n",
    "    df.drop_duplicates(subset = \"TRIP_ID\", keep = keep_last, inplace = True) #TRIP_ID duplicates are dropped as TRIP_IDs are unique\n",
    "    df = df[df[\"MISSING_DATA\"] == 0] #Remove all data with missing coordinates\n",
    "    df.drop(\"MISSING_DATA\", axis = 1, inplace = True) #All missing coordinates removed, MISSING_DATA column can be removed\n",
    "    df.drop(\"DAY_TYPE\", axis = 1, inplace=True) #DAY_TYPE is removed as all values are 'A'\n",
    "    df = df[df[\"POLYLINE\"] != \"[]\"]\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "taxi = initial_clean(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. Write both list_coordiantes and convert_coordinates function to use them both to convert 'POLYLINE' from a str into a list.\n",
    "import json \n",
    "def list_coordinates(string):\n",
    "        \"\"\"\n",
    "        Loads list of coordinates from given string and swap out longitudes & latitudes.\n",
    "        Swapping is done because the standard is to have latitude values first, but\n",
    "        the coordiantes given is backwards.\n",
    "        \"\"\"\n",
    "        return [(lat, long) for (long, lat) in json.loads(string)] # json.loads convent strs into a json object (i.e list/dict)\n",
    "def convert_coordinates(df):\n",
    "    \"\"\"\n",
    "    Transforming the POLYLINE values from a string into a list\n",
    "    \"\"\"\n",
    "    df['POLYLINE'] = df['POLYLINE'].apply(list_coordinates) #maps through and coverts str into list for each row in 'POLYLINE' \n",
    "    return df\n",
    "\n",
    "taxi = convert_coordinates(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. Write start_pos function and use it to extract the coordinates for the start point\n",
    "def start_pos(df):\n",
    "    \"\"\"\n",
    "    Returns back the first lat and longs in the 'POLYLINE' in two seperate\n",
    "    columns, with labels 'START_LAT' for latitudes and 'START_LONG'\n",
    "    for longitudes.\n",
    "    \"\"\"\n",
    "    df['START_LAT'] = df['POLYLINE'].apply(lambda x: x[0][0]) #extracts the first latitude in the polyline\n",
    "    df['START_LONG'] = df['POLYLINE'].apply(lambda x: x[0][1])#extracts the first longitude in the polyline\n",
    "    return df\n",
    "\n",
    "taxi = start_pos(taxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#4. Write last_pos function and use it to extract the last coordinate for of the 'POLYLINE'\n",
    "# Note: last_pos() extracts destination for the training set but last coordiante of truncated 'POLYLINE' for test set\n",
    "def last_pos(df, lat_label, long_label):\n",
    "    \"\"\"\n",
    "    Returns back the last lat and longs in the 'POLYLINE' in two seperate\n",
    "    columns, with labels define in lat_label for latitudes \n",
    "    and long_label for longitudes.\n",
    "    \"\"\"\n",
    "    df[lat_label] = df['POLYLINE'].apply(lambda x: x[-1][0])\n",
    "    df[long_label] = df['POLYLINE'].apply(lambda x: x[-1][1])\n",
    "    return df\n",
    "\n",
    "taxi = last_pos(taxi, \"END_LAT\", \"END_LONG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5. Write date_time function and use it to extract the week, day and quarter hour of the trips\n",
    "def date_time(df):\n",
    "    \"\"\"\n",
    "    Convert unxi time in seconds to datetime and spliting them\n",
    "    into 'WEEK', 'DAY', 'HOUR'\n",
    "    \"\"\"\n",
    "    df['date_time'] = pd.to_datetime(df['TIMESTAMP'],unit='s')\n",
    "    df[\"WEEK\"] = df[\"date_time\"].map(lambda x : x.weekofyear) #total 52 weeks in a year\n",
    "    df[\"DAY\"] = df[\"date_time\"].map(lambda x : x.dayofweek) # total 7 days in a week Mon = 0 and Sun = 6\n",
    "    df[\"Q_HOUR\"] = df[\"date_time\"].map(lambda x : x.hour* 4 + x.minute / 15) \n",
    "    return df\n",
    "\n",
    "taxi = date_time(taxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another than the training set, cleaning will be applied to the test set too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = initial_clean(test)\n",
    "test = convert_coordinates(test)\n",
    "taxi = last_pos(taxi, \"END_LAT\", \"END_LONG\")\n",
    "test = start_pos(test)\n",
    "test = date_time(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "taxi.to_pickle('./Pickles/taxi_cleaned') #pickling cleaned trainset for to be used for EDA\n",
    "test.to_pickle('./Pickles/test_cleaned') #pickling cleaned testset for to be used for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
